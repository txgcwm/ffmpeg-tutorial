\chapter{播放音频}
\label{ch3}
\section{音频}
现在我们要来播放音频。SDL也为我们准备了输出音频的方法。函数SDL_OpenAudio()本身就是用来打开音频设备的。它使用一个叫做SDL_AudioSpec 结构体作为参数，这个结构体中包含了我们将要输出的音频的所有信息。

在我们展示如何建立之前，让我们先解释一下电脑是如何处理音频的。数字音频是由一长串的\textbf{样本}（samples）流组成的。每个样本表示音频波形中的一个值。音频按照一个特定的\textbf{采样率}{sample rate}来进行录制，采样率表示以多快的速度来播放这段样本流，它的表示方式为每秒多少次采样。例如22050 和44100的采样率就是电台和CD常用的采样率。此外，大多音频有不只一个通道来表示立体声或者环绕。例如，如果采样是立体声，那么每次的采样数就为2个。当我们从一个电影文件中得到数据的时候，我们不知道我们将得到多少个样本，但是ffmpeg 将不会给我们部分的样本——这意味着它将不会把立体声分割开来。

SDL播放音频的方式是这样的：你先设置音频的选项：采样率（在SDL的结构体中叫做“freq”，代指\textbf{frequency}），通道数和其它的参数，然后我们设置一个回调函数和一些用户数据（userdata）。当开始播放音频的时候，SDL将不断地调用这个回调函数并且要求它来向音频缓冲填入特定的数量的字节。当我们把这些信息放到SDL_AudioSpec 结构体中后，调用函数SDL_OpenAudio() 就会打开音频设备并且给我们返回\emph{另一个}AudioSpec 结构体。（结构体中的）这些音频指标（specs）是我们会\emph{实际}用到的——因为我们无法保证可以得到所要求的指标。

\section{设置音频}

目前先把讲的记住，因为我们实际上还没有任何关于音频流的信息。让我们回过头来看一下我们的代码，看我们是如何找到视频流的，同样我们也可以找到音频流。

\begin{lstlisting}
// Find the first video stream
videoStream=-1;
audioStream=-1;
for(i=0; i < pFormatCtx->nb_streams; i++) {
  if(pFormatCtx->streams[i]->codec->codec_type==CODEC_TYPE_VIDEO
     &&
       videoStream < 0) {
    videoStream=i;
  }
  if(pFormatCtx->streams[i]->codec->codec_type==CODEC_TYPE_AUDIO &&
     audioStream < 0) {
    audioStream=i;
  }
}
if(videoStream==-1)
  return -1; // Didn't find a video stream
if(audioStream==-1)
  return -1;
\end{lstlisting}

从这里我们可以从描述流的AVCodecContext 中得到我们想要的信息，就像我们得到视频流的信息一样。

\begin{lstlisting}
AVCodecContext *aCodecCtx;

aCodecCtx=pFormatCtx->streams[audioStream]->codec;
\end{lstlisting}

包含在编解码上下文中的所有信息正是我们所需要的用来建立音频的信息：

\begin{lstlisting}
wanted_spec.freq = aCodecCtx->sample_rate;
wanted_spec.format = AUDIO_S16SYS;
wanted_spec.channels = aCodecCtx->channels;
wanted_spec.silence = 0;
wanted_spec.samples = SDL_AUDIO_BUFFER_SIZE;
wanted_spec.callback = audio_callback;
wanted_spec.userdata = aCodecCtx;

if(SDL_OpenAudio(&wanted_spec, &spec) < 0) {
  fprintf(stderr, "SDL_OpenAudio: %s\n", SDL_GetError());
  return -1;
}
\end{lstlisting}

让我们浏览一下这些：
\begin{itemize}
  \item freq：前面所讲的采样率

  \item format：告诉SDL我们将要给的格式。“S16SYS”中的S表示有符号的signed，16表示每个样本是16位长的，SYS表示大小端的顺序是与使用的系统相同的。这些格式是由avcodec_decode_audio2为我们给出来的输入音频的格式。

  \item channels：音频的通道数

  \item silence：这是用来表示静音的值。因为音频采样是有符号的，所以0当然就是这个值。

  \item samples：这是当我们想要更多音频的时候，我们想让SDL给出来的音频缓冲区的尺寸。一个比较合适的值在512到8192之间；ffplay使用1024。

  \item callback：这个是我们的回调函数。我们后面将会详细讨论。

  \item userdata：这个是SDL供给回调函数运行的参数。我们将让回调函数得到整个编解码的上下文；你将在后面知道这样做的原因。

\end{itemize}

最后，我们使用SDL_OpenAudio 函数来打开音频。

如果你还记得前面的教程，我们仍然需要打开音频编解码器本身。这是很显然的。

\begin{lstlisting}
AVCodec         *aCodec;

aCodec = avcodec_find_decoder(aCodecCtx->codec_id);
if(!aCodec) {
  fprintf(stderr, "Unsupported codec!\n");
  return -1;
}
avcodec_open(aCodecCtx, aCodec);
\end{lstlisting}
\section{队列}

嗯！现在我们已经准备好从流中取出音频信息。但是我们如何来处理这些信息呢？我们将会不断地从文件中得到这些包，但同时SDL 也将调用回调函数。解决方法为创建一个全局的结构体变量以便于我们从文件中得到的音频包有地方存放同时也保证SDL中的音频回调函数audio_callback能从这个地方得到音频数据。所以我们要做的是创建一个包的\textbf{队列}（queue）。在ffmpeg中有一个叫AVPacketList 的结构体可以帮助我们，这个结构体实际是一串包的链表。下面就是我们的队列结构体：

\begin{lstlisting}
typedef struct PacketQueue {
  AVPacketList *first_pkt, *last_pkt;
  int nb_packets;
  int size;
  SDL_mutex *mutex;
  SDL_cond *cond;
} PacketQueue;
\end{lstlisting}

首先，我们应当指出nb_packets与size是不一样的，size表示我们从packet->size中得到的字节数。你会注意到我们有一个互斥量mutex和一个条件变量cond在结构体里面。这是因为SDL是在一个独立的线程中来进行音频处理的。如果我们没有正确的锁定这个队列，我们有可能把数据搞乱。我们来看这样一个队列实现是什么样的。每一个程序员应当知道如何来创建的一个队列，但是我们将把这部分也来讨论从而可以学习到SDL的函数。

一开始我们先创建一个函数来初始化队列：
\begin{lstlisting}
void packet_queue_init(PacketQueue *q) {
  memset(q, 0, sizeof(PacketQueue));
  q->mutex = SDL_CreateMutex();
  q->cond = SDL_CreateCond();
}
\end{lstlisting}

接着我们再写一个函数来给队列中填入东西：
\begin{lstlisting}
int packet_queue_put(PacketQueue *q, AVPacket *pkt) {

  AVPacketList *pkt1;
  if(av_dup_packet(pkt) < 0) {
    return -1;
  }
  pkt1 = av_malloc(sizeof(AVPacketList));
  if (!pkt1)
    return -1;
  pkt1->pkt = *pkt;
  pkt1->next = NULL;


  SDL_LockMutex(q->mutex);

  if (!q->last_pkt)
    q->first_pkt = pkt1;
  else
    q->last_pkt->next = pkt1;
  q->last_pkt = pkt1;
  q->nb_packets++;
  q->size += pkt1->pkt.size;
  SDL_CondSignal(q->cond);

  SDL_UnlockMutex(q->mutex);
  return 0;
}
\end{lstlisting}

函数SDL_LockMutex()锁定队列的互斥量以便于我们向队列中添加东西，然后函数SDL_CondSignal()通过我们的条件变量为一个接收函数（如果它在等待）发出一个信号来告诉它现在已经有数据了，接着就会解锁互斥量并让队列可以自由访问。

下面是相应的接收函数。注意函数SDL_CondWait()是如何按照我们的要求让函数\textbf{阻塞}（block）的（例如一直等到队列中有数据）。
\begin{lstlisting}
int quit = 0;

static int packet_queue_get(PacketQueue *q, AVPacket *pkt, int block) {
  AVPacketList *pkt1;
  int ret;

  SDL_LockMutex(q->mutex);

  for(;;) {

    if(quit) {
      ret = -1;
      break;
    }

    pkt1 = q->first_pkt;
    if (pkt1) {
      q->first_pkt = pkt1->next;
      if (!q->first_pkt)
        q->last_pkt = NULL;
      q->nb_packets--;
      q->size -= pkt1->pkt.size;
      *pkt = pkt1->pkt;
      av_free(pkt1);
      ret = 1;
      break;
    } else if (!block) {
      ret = 0;
      break;
    } else {
      SDL_CondWait(q->cond, q->mutex);
    }
  }
  SDL_UnlockMutex(q->mutex);
  return ret;
}
\end{lstlisting}

正如你所看到的，我们已经用一个无限循环包装了这个函数以便于我们想用阻塞的方式来得到数据。我们通过使用SDL中的函数SDL_CondWait()来避免无限循环。基本上，所有的CondWait只等待从SDL_CondSignal()函数（或者SDL_CondBroadcast()函数）中发出的信号，然后再继续执行。然而，虽然看起来我们陷入了我们的互斥体中——如果我们一直保持着这个锁，我们的函数将永远无法把数据放入到队列中去！但是，SDL_CondWait()函数也为我们做了解锁互斥量的动作然后才尝试着在得到信号后去重新锁定它。

\section{意外情况}

你们将会注意到我们有一个全局变量quit，我们用它来保证还没有设置程序退出的信号（SDL会自动处理TERM类似的信号）。否则，这个线程将不停地运行直到我们使用kill -9来结束程序。FFMPEG同样也提供了一个函数来进行回调并检查我们是否需要退出一些被阻塞的函数：这个函数就是：url_set_interrupt_cb。

\begin{lstlisting}
int decode_interrupt_cb(void) {
  return quit;
}
...
main() {
...
  url_set_interrupt_cb(decode_interrupt_cb);
...
  SDL_PollEvent(&event);
  switch(event.type) {
  case SDL_QUIT:
    quit = 1;
...
\end{lstlisting}

当然，这仅仅是用来给ffmpeg中的阻塞情况使用的，而不是SDL中的。我们还必需要设置quit 标志为1。

\section{为队列提供包}


剩下的我们唯一需要为队列所做的事就是提供包了：

\begin{lstlisting}
PacketQueue audioq;
main() {
...
  avcodec_open(aCodecCtx, aCodec);

  packet_queue_init(&audioq);
  SDL_PauseAudio(0);
\end{lstlisting}

函数SDL_PauseAudio()让音频设备最终开始工作。如果没有立即供给足够的数据，它会播放静音。我们已经建立好我们的队列，现在我们准备为它提供包。先看一下我们的读取包的循环：

\begin{lstlisting}
while(av_read_frame(pFormatCtx, &packet)>=0) {
  // Is this a packet from the video stream?
  if(packet.stream_index==videoStream) {
    // Decode video frame
    ....
    }
  } else if(packet.stream_index==audioStream) {
    packet_queue_put(&audioq, &packet);
  } else {
    av_free_packet(&packet);
  }
\end{lstlisting}

注意：我们没有在把包放到队列里的时候释放它，我们将在解码后来释放它。

\section{取出包}

我们最后再来让音频回调函数audio_callback从队列中取出包。回调函数的格式必需为void callback(void *userdata, Uint8 *stream, int len)，这里的userdata就是我们给SDL的指针，stream是我们要把音频数据写入的缓冲区指针，len是缓冲区的大小。代码如下：

\begin{lstlisting}
void audio_callback(void *userdata, Uint8 *stream, int len) {

  AVCodecContext *aCodecCtx = (AVCodecContext *)userdata;
  int len1, audio_size;

  static uint8_t audio_buf[(AVCODEC_MAX_AUDIO_FRAME_SIZE * 3) / 2];
  static unsigned int audio_buf_size = 0;
  static unsigned int audio_buf_index = 0;

  while(len > 0) {
    if(audio_buf_index >= audio_buf_size) {
      /* We have already sent all our data; get more */
      audio_size = audio_decode_frame(aCodecCtx, audio_buf,
                                      sizeof(audio_buf));
      if(audio_size < 0) {
    /* If error, output silence */
    audio_buf_size = 1024;
    memset(audio_buf, 0, audio_buf_size);
      } else {
    audio_buf_size = audio_size;
      }
      audio_buf_index = 0;
    }
    len1 = audio_buf_size - audio_buf_index;
    if(len1 > len)
      len1 = len;
    memcpy(stream, (uint8_t *)audio_buf + audio_buf_index, len1);
    len -= len1;
    stream += len1;
    audio_buf_index += len1;
  }
}
\end{lstlisting}

这基本上是一个简单的从另外一个我们将要写的audio_decode_frame()函数中获取数据的循环，这个循环把结果写入到中间缓冲区，尝试着向流中写入len字节并且在我们没有足够的数据的时候会获取更多的数据或者当我们有多余数据的时候保存下来为后面使用。这个audio_buf 的大小为1.5倍的音频帧的大小以便于有一个比较好的缓冲，这个音频帧的大小是ffmpeg给出的。

\section{最后解码音频}
让我们看一下解码器的真正部分：audio_decode_frame：
\begin{lstlisting}
int audio_decode_frame(AVCodecContext *aCodecCtx, uint8_t *audio_buf,
                       int buf_size) {

  static AVPacket pkt;
  static uint8_t *audio_pkt_data = NULL;
  static int audio_pkt_size = 0;

  int len1, data_size;

  for(;;) {
    while(audio_pkt_size > 0) {
      data_size = buf_size;
      len1 = avcodec_decode_audio2(aCodecCtx, (int16_t *)audio_buf, &data_size,
                  audio_pkt_data, audio_pkt_size);
      if(len1 < 0) {
    /* if error, skip frame */
    audio_pkt_size = 0;
    break;
      }
      audio_pkt_data += len1;
      audio_pkt_size -= len1;
      if(data_size <= 0) {
    /* No data yet, get more frames */
    continue;
      }
      /* We have data, return it and come back for more later */
      return data_size;
    }
    if(pkt.data)
      av_free_packet(&pkt);

    if(quit) {
      return -1;
    }

    if(packet_queue_get(&audioq, &pkt, 1) < 0) {
      return -1;
    }
    audio_pkt_data = pkt.data;
    audio_pkt_size = pkt.size;
  }
}
\end{lstlisting}

整个过程实际上从函数的尾部开始，在这里我们调用了packet_queue_get()函数。我们从队列中取出包，并且保存它的信息。然后，一旦我们有了可以使用的包，我们就调用函数avcodec_decode_audio2()，它的功能就像它的姐妹函数avcodec_decode_video() 一样，唯一的区别是它的一个包里可能有不止一个音频帧，所以你可能要调用很多次来解码出包中所有的数据。同时也要记住进行指针audio_buf的强制转换，因为SDL给出的是8位整型缓冲指针而ffmpeg给出的数据是16位的整型指针。你应该也会注意到len1和data_size的不同，len1表示解码使用的数据的在包中的大小，data_size表示实际返回的原始音频数据的大小。

\marginpar{\rule[-15mm]{0.4mm}{15mm}}{\textbf{备注：}\small 为什么使用avcodec_decode_audio2()？因为曾经有一个avcodec_decode_audio()，但现在被废弃了。这个新的函数通过data_size变量来算出从audio_buf读取多少数据。}

当我们得到一些数据的时候，我们立刻返回来看一下是否仍然需要从队列中得到更加多的数据或者我们已经完成了。如果我们仍然有更加多的数据要处理，我们把它保存到下一次。如果我们完成了一个包的处理，我们最后要释放它。

就是这样。我们利用主的读取队列循环从文件得到音频并送到队列中，然后被audio_callback函数从队列中读取并处理，最后把数据送给SDL，于是SDL就相当于我们的声卡。让我们继续并且编译：

\begin{lstlisting}
gcc -o tutorial03 tutorial03.c -lavutil -lavformat -lavcodec -lz -lm \
`sdl-config --cflags --libs`
\end{lstlisting}

啊哈！视频虽然还是像原来那样快，但是音频可以正常播放了。这是为什么呢？因为音频信息中带有采样率信息——虽然我们把音频数据尽可能快的填充到声卡缓冲中，但是音频设备却会按照原来流中指定的采样率来进行播放。

我们几乎已经准备好来开始同步音频和视频了，但是首先我们需要一些程序的梳理工作。用队列来处理音频和在独立的线程中播放音频的方法效果很好：它使得程序更加更加易于控制和模块化。在我们开始同步音视频之前，我们需要让我们的代码更加易于处理。所以下次要讲的是：创建线程。
